# üîç GPT-5 Bug Report & Implementation Comparison

## Executive Summary

Nova CI-Rescue was failing with GPT-5 due to incompatible message role types. GPT-5 doesn't support the `"function"` role that GPT-4 uses for structured tool calling. This report details the bug, our fix, and compares it with an alternative implementation approach.

---

## üêõ The Bug: What Happened?

### Root Cause

```
openai.BadRequestError: Error code: 400 - {'error': {'message':
"Unsupported value: 'messages[3].role' does not support 'function' with this model."
```

### Technical Explanation

1. **Model Mismatch**: Nova was defaulting to GPT-5 but using GPT-4's function-calling paradigm
2. **Message Role Incompatibility**:
   - GPT-4 supports: `system`, `user`, `assistant`, `function` roles
   - GPT-5 supports: `system`, `user`, `assistant` roles only
3. **Agent Type Issue**: The code detected GPT-5 and set `use_react = True`, but then ignored this flag and always used `AgentType.OPENAI_FUNCTIONS`

### Code Flow That Caused the Bug

```python
# In deep_agent.py (BEFORE fix):
if model_name == "gpt-5":
    use_react = True  # ‚úÖ Correctly detected GPT-5

# But then...
agent_executor = initialize_agent(
    agent=AgentType.OPENAI_FUNCTIONS,  # ‚ùå Always used function calling!
    # This sends 'function' role messages that GPT-5 rejects
)
```

### Impact

- Nova would crash immediately when trying to use GPT-5
- No fallback mechanism existed
- Environment variables were ignored
- Users couldn't easily switch models

---

## üîß Our Implementation vs. Suggested Implementation

### **1. ReAct Pattern Fix**

#### Our Implementation ‚úÖ

```python
if use_react:
    # For GPT-5 and other models that don't support function calling
    agent_executor = initialize_agent(
        agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
        agent_kwargs={
            "prefix": system_message + "\n\nYou have access to the following tools:",
            "format_instructions": "Use the following format:\n\nThought:..."
        }
    )
else:
    # For GPT-4 and other models that support function calling
    agent_executor = initialize_agent(
        agent=AgentType.OPENAI_FUNCTIONS,
        ...
    )
```

#### Suggested Implementation üìù

```python
if model_name.lower().startswith("gpt-5"):  # Broader detection
    use_react = True
```

**Key Differences:**

- **Ours**: Exact match for "gpt-5"
- **Theirs**: Catches variants like "gpt-5-turbo", "gpt-5-preview"
- **Advantage of Theirs**: More future-proof for GPT-5 variants

---

### **2. Environment Variable Support**

#### Our Implementation ‚úÖ

```python
# In cli.py
if config_data and config_data.model:
    settings.default_llm_model = config_data.model
else:
    import os
    env_model = os.getenv("NOVA_MODEL") or os.getenv("NOVA_LLM_MODEL") or os.getenv("MODEL")
    if env_model:
        settings.default_llm_model = env_model
```

#### Suggested Implementation üìù

```python
# In config.py - at module level
env_model = os.getenv("NOVA_MODEL") or os.getenv("NOVA_LLM_MODEL")
if env_model:
    settings.default_llm_model = env_model
```

**Key Differences:**

- **Ours**: Checks env vars in CLI after config file load
- **Theirs**: Suggests checking in config.py during settings initialization
- **Ours**: Also checks generic "MODEL" env var for compatibility
- **Advantage of Ours**: More flexible, supports legacy MODEL env var

---

### **3. Fallback Mechanism**

#### Our Implementation ‚úÖ

```python
# In deep_agent.py initialization
if model_name == "gpt-5":
    try:
        llm = ChatOpenAI(model_name="gpt-5", temperature=0)
        use_react = True
    except Exception as e:
        if self.verbose:
            print(f"‚ö†Ô∏è GPT-5 not available ({e}), falling back to GPT-4")
        llm = ChatOpenAI(model_name="gpt-4", temperature=0)
        use_react = False
```

#### Suggested Implementation üìù

```python
# Runtime fallback in run() method
try:
    result = self.agent({"input": user_prompt})
except Exception as e:
    if "gpt-5" in self.settings.default_llm_model.lower():
        if self.verbose:
            print("‚ö†Ô∏è GPT-5 failed, falling back to GPT-4")
        self.settings.default_llm_model = "gpt-4"
        self.agent = self._build_agent()  # rebuild with GPT-4
        result = self.agent({"input": user_prompt})
    else:
        raise
```

**Key Differences:**

- **Ours**: Fallback during initialization only
- **Theirs**: Runtime fallback during execution
- **Advantage of Theirs**: Can recover from mid-execution failures
- **Advantage of Ours**: Simpler, less overhead

---

### **4. Configuration Alias**

#### Our Implementation ‚úÖ

```yaml
# nova.config.yml
default_llm_model: gpt-5
```

#### Suggested Implementation üìù

```yaml
# nova.config.yml (with alias support)
model: gpt-5 # Maps to default_llm_model internally
```

**Key Differences:**

- **Ours**: Uses the actual field name
- **Theirs**: Suggests adding "model" as an alias
- **Advantage of Theirs**: More user-friendly, matches documentation

---

## üìä Comparison Summary

| Feature                  | Our Implementation    | Suggested Implementation | Winner                 |
| ------------------------ | --------------------- | ------------------------ | ---------------------- |
| **ReAct Pattern Fix**    | ‚úÖ Fixed, exact match | Broader pattern match    | Theirs (more flexible) |
| **Env Variable Support** | ‚úÖ Complete, 3 vars   | 2 vars, module-level     | Ours (more options)    |
| **Fallback Mechanism**   | Init-time only        | Runtime + init-time      | Theirs (more robust)   |
| **Config Alias**         | Direct field name     | User-friendly alias      | Theirs (better UX)     |
| **Code Complexity**      | Simple, focused       | More comprehensive       | Tie                    |
| **Implementation Speed** | ‚úÖ Quick fix          | More changes needed      | Ours                   |

---

## üéØ Recommended Enhancements

Based on the comparison, here are improvements we could add:

### 1. **Broader Model Detection**

```python
# Better pattern matching for GPT-5 variants
if model_name.lower().startswith("gpt-5") or model_name in ["gpt-5-turbo", "gpt-5-preview"]:
    use_react = True
```

### 2. **Runtime Fallback**

Add try/catch in the run() method for mid-execution recovery:

```python
def run(self, ...):
    try:
        result = self.agent({"input": user_prompt})
    except openai.BadRequestError as e:
        if "function" in str(e) and self.can_fallback:
            return self._fallback_to_gpt4(user_prompt)
        raise
```

### 3. **Config Alias Support**

```python
# In NovaSettings.from_yaml()
if "model" in data:
    data["default_llm_model"] = data.pop("model")
```

### 4. **Model Capability Registry**

```python
MODEL_CAPABILITIES = {
    "gpt-4": {"function_calling": True, "max_tokens": 8192},
    "gpt-5": {"function_calling": False, "max_tokens": 16384},
    "gpt-5-turbo": {"function_calling": False, "max_tokens": 16384},
}
```

---

## üöÄ Current Status

### ‚úÖ What Works Now

1. GPT-5 successfully uses ReAct pattern (no function calls)
2. Environment variables work (`NOVA_MODEL`, `NOVA_LLM_MODEL`, `MODEL`)
3. Config file supports model selection
4. Basic fallback during initialization
5. Clear error messages and debugging output

### üîÑ What Could Be Enhanced

1. Runtime fallback for mid-execution failures
2. Broader GPT-5 variant detection
3. User-friendly "model" alias in config
4. Model capability registry for cleaner code

---

## üìù Conclusion

Both implementations solve the core bug, but with different philosophies:

- **Our approach**: Minimal, surgical fix that gets GPT-5 working quickly
- **Their approach**: Comprehensive, future-proof solution with better error recovery

The suggested implementation is more robust for production use, while ours is a pragmatic fix that works immediately. The ideal solution would combine both: our quick env var support with their runtime fallback and broader pattern matching.

### Recommendation

For immediate use: Our implementation is sufficient and tested.
For production deployment: Consider adding the runtime fallback and broader model detection from the suggested implementation.

---

## üîó Testing Commands

```bash
# Test with GPT-5 (config file)
nova fix . --verbose

# Test with GPT-4 fallback
NOVA_MODEL=gpt-4 nova fix . --verbose

# Test with explicit GPT-5
NOVA_MODEL=gpt-5 nova fix . --verbose

# Verify ReAct pattern is used
# Look for: "üöÄ Using GPT-5 model with ReAct pattern"
```
